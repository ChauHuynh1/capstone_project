{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764ad313",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b44d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e80fa4",
   "metadata": {},
   "source": [
    "# Remove background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14b9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def remove_background(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a mask with all zeros\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "\n",
    "    # Define the background and foreground model using the GrabCut algorithm\n",
    "    bgdModel = np.zeros((1,65), np.float64)\n",
    "    fgdModel = np.zeros((1,65), np.float64)\n",
    "\n",
    "    # Define the rectangle that contains the object of interest\n",
    "    height, width = image.shape[:2]\n",
    "    rect = (10, 10, width-10, height-10)\n",
    "\n",
    "    # Apply the GrabCut algorithm to the image and mask\n",
    "    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    # Create a mask where the background is 0 and the object of interest is 1\n",
    "    mask = np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n",
    "\n",
    "    # Apply the mask to the original image to remove the background\n",
    "    image = image*mask[:,:,np.newaxis]\n",
    "\n",
    "    # Save the image without the background\n",
    "    new_image_path = os.path.splitext(image_path)[0] + '_nobg.jpg'\n",
    "    cv2.imwrite(new_image_path, image)\n",
    "\n",
    "    return new_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559a2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Image\n",
      "0    data/Thermal/snap_1_ (119).jpg\n",
      "1    data/Thermal/snap_1_ (300).jpg\n",
      "2     data/Thermal/snap_1_ (25).jpg\n",
      "3    data/Thermal/snap_1_ (194).jpg\n",
      "4    data/Thermal/snap_1_ (143).jpg\n",
      "..                              ...\n",
      "425  data/Thermal/snap_1_ (212).jpg\n",
      "426  data/Thermal/snap_1_ (121).jpg\n",
      "427   data/Thermal/snap_1_ (30).jpg\n",
      "428  data/Thermal/snap_1_ (155).jpg\n",
      "429   data/Thermal/snap_1_ (62).jpg\n",
      "\n",
      "[430 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_dir = \"data/Thermal\"\n",
    "images = []\n",
    "image_paths = []\n",
    "new_image_size = (256, 256)  # set the size of the new images\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize the image to the desired size\n",
    "        resized_image = cv2.resize(image, new_image_size)\n",
    "\n",
    "        # Flatten the image into a 1D array\n",
    "        flattened_image = resized_image.flatten()\n",
    "\n",
    "        # Append the flattened image and image path to the respective lists\n",
    "        images.append(flattened_image)\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "# Convert the image and image path lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "image_paths = np.array(image_paths)\n",
    "\n",
    "# Shuffle the data\n",
    "images, image_paths = shuffle(images, image_paths, random_state=42)\n",
    "\n",
    "# Create a DataFrame from the image and image path arrays\n",
    "df = pd.DataFrame({'Image': image_paths})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ec8900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"data/Thermal\"\n",
    "preprocessed_dir = \"preprocessed_data\"\n",
    "new_image_size = (256, 256)  # set the size of the new images\n",
    "new_image_path = \"preprocessed_data\"  # Specify the new folder name\n",
    "# Create the new directory if it doesn't exist\n",
    "os.makedirs(new_image_path, exist_ok=True)\n",
    "\n",
    "# Create the preprocessed data directory if it doesn't exist\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize the image to the desired size\n",
    "        resized_image = cv2.resize(image, new_image_size)\n",
    "\n",
    "        # Apply image enhancement\n",
    "        enhanced_image = cv2.equalizeHist(resized_image)\n",
    "\n",
    "        # Apply noise reduction\n",
    "        blurred_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "\n",
    "        # Apply temperature normalization\n",
    "        normalized_image = cv2.normalize(blurred_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # Apply thresholding and segmentation\n",
    "        _, thresholded_image = cv2.threshold(normalized_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Crop the solar panel into multiple cells\n",
    "        cell_images = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cell_image = resized_image[y:y+h, x:x+w]\n",
    "            cell_images.append(cell_image)\n",
    "\n",
    "        # Save each cell as a separate image\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        for i, cell_image in enumerate(cell_images):\n",
    "            cell_filename = f\"{base_filename}_cell{i+1}.jpg\"\n",
    "            cell_filepath = os.path.join(new_image_path, cell_filename)\n",
    "            cv2.imwrite(cell_filepath, cell_image)\n",
    "\n",
    "# Print a message after preprocessing all the images\n",
    "print(\"Preprocessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2be7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03bb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f26dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35501ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fec46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
